# _*_ coding : utf-8 _*_
# @Time : 2025-01-12
# @Description : æ•´åˆlabelmeè½¬æ¢ã€æ•°æ®é›†åˆ†å‰²ã€é…ç½®ç”Ÿæˆçš„å®Œæ•´YOLOè®­ç»ƒç®¡é“

import os
import json
import shutil
import random
import argparse
from datetime import datetime
from sklearn.model_selection import train_test_split




def convert_labelme_to_yolo(json_path, output_dir, label_map):
    """
    å°† Labelme æ ¼å¼çš„ JSON æ–‡ä»¶è½¬æ¢ä¸º YOLO11 æ ¼å¼çš„ TXT æ–‡ä»¶ã€‚
    """
    try:
        # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦ä¸ºç©º
        if os.path.getsize(json_path) == 0:
            print(f"Warning: è·³è¿‡ç©ºæ–‡ä»¶ {json_path}")
            return False
        
        # æ‰“å¼€ Labelme æ ¼å¼çš„ JSON æ–‡ä»¶
        with open(json_path, 'r', encoding='utf-8') as f:
            content = f.read().strip()
            if not content:
                print(f"Warning: è·³è¿‡ç©ºå†…å®¹æ–‡ä»¶ {json_path}")
                return False
            
            try:
                labelme_data = json.loads(content)
            except json.JSONDecodeError as e:
                print(f"Warning: JSONè§£æå¤±è´¥ï¼Œè·³è¿‡æ–‡ä»¶ {json_path}: {e}")
                return False
    except Exception as e:
        print(f"Warning: è¯»å–æ–‡ä»¶å¤±è´¥ï¼Œè·³è¿‡æ–‡ä»¶ {json_path}: {e}")
        return False

    # éªŒè¯JSONç»“æ„
    required_keys = ['imageWidth', 'imageHeight', 'shapes']
    for key in required_keys:
        if key not in labelme_data:
            print(f"Warning: JSONæ–‡ä»¶ç¼ºå°‘å¿…éœ€å­—æ®µ '{key}'ï¼Œè·³è¿‡æ–‡ä»¶ {json_path}")
            return False
    
    # è·å–å›¾åƒçš„å®½åº¦å’Œé«˜åº¦
    try:
        image_width = labelme_data['imageWidth']
        image_height = labelme_data['imageHeight']
        
        if image_width <= 0 or image_height <= 0:
            print(f"Warning: å›¾åƒå°ºå¯¸æ— æ•ˆ (å®½:{image_width}, é«˜:{image_height})ï¼Œè·³è¿‡æ–‡ä»¶ {json_path}")
            return False
            
    except (KeyError, TypeError, ValueError) as e:
        print(f"Warning: è·å–å›¾åƒå°ºå¯¸å¤±è´¥ï¼Œè·³è¿‡æ–‡ä»¶ {json_path}: {e}")
        return False

    yolo_annotations = []  # å­˜å‚¨ YOLO11 æ ¼å¼çš„æ ‡æ³¨

    # éå†æ‰€æœ‰çš„æ ‡æ³¨å½¢çŠ¶
    for shape in labelme_data['shapes']:
        label = shape['label'].strip()  # è·å–æ ‡ç­¾åç§°
        if label not in label_map:
            print(f"Warning: æ ‡ç­¾ '{label}' æœªåœ¨æ ‡ç­¾æ˜ å°„ä¸­ï¼Œè·³è¿‡æ­¤æ ‡æ³¨")
            continue  # å¦‚æœæ ‡ç­¾æœªå®šä¹‰ï¼Œåˆ™å¿½ç•¥

        class_id = label_map[label]  # è·å–å¯¹åº”çš„ç±»åˆ« ID
        points = shape['points']  # è·å–æ ‡æ³¨çš„åæ ‡ç‚¹

        if shape['shape_type'] == 'rectangle':  # å¦‚æœæ˜¯çŸ©å½¢
            x1, y1 = min(point[0] for point in points), min(point[1] for point in points)
            x2, y2 = max(point[0] for point in points), max(point[1] for point in points)

        elif shape['shape_type'] == 'polygon':  # å¦‚æœæ˜¯å¤šè¾¹å½¢
            x1, y1 = min(point[0] for point in points), min(point[1] for point in points)
            x2, y2 = max(point[0] for point in points), max(point[1] for point in points)

        elif shape['shape_type'] == 'circle':  # å¤„ç†åœ†å½¢æ ‡æ³¨
            # åœ†å½¢çš„ä¸¤ä¸ªç‚¹åˆ†åˆ«æ˜¯åœ†å¿ƒå’Œåœ†ä¸Šçš„æŸä¸ªç‚¹ï¼Œè®¡ç®—åœ†çš„åŠå¾„
            (cx, cy), (x, y) = points
            # è®¡ç®—åŠå¾„
            r = ((x - cx) ** 2 + (y - cy) ** 2) ** 0.5
            # è®¡ç®—æœ€å°å¤–æ¥çŸ©å½¢
            x1 = cx - r
            y1 = cy - r
            x2 = cx + r
            y2 = cy + r

        else:
            print(f"Warning: ä¸æ”¯æŒçš„æ ‡æ³¨ç±»å‹ '{shape['shape_type']}'ï¼Œè·³è¿‡æ­¤æ ‡æ³¨")
            continue  # å…¶ä»–ç±»å‹ä¸å¤„ç†

        # è®¡ç®— YOLO11 æ ¼å¼æ‰€éœ€çš„ä¸­å¿ƒç‚¹å’Œå®½é«˜
        x_center = max(0, (x1 + x2) / 2.0 / image_width)
        y_center = max(0, (y1 + y2) / 2.0 / image_height)
        width = max(0, (x2 - x1) / image_width)
        height = max(0, (y2 - y1) / image_height)

        # æ·»åŠ  YOLO11 æ ¼å¼çš„æ ‡æ³¨åˆ°åˆ—è¡¨ä¸­
        yolo_annotations.append(f"{class_id} {x_center:.6f} {y_center:.6f} {width:.6f} {height:.6f}")

    # æ„å»ºè¾“å‡ºæ–‡ä»¶çš„è·¯å¾„
    output_file = os.path.join(output_dir, os.path.splitext(os.path.basename(json_path))[0] + '.txt')
    # å°† YOLO11 æ ¼å¼çš„æ ‡æ³¨å†™å…¥è¾“å‡ºæ–‡ä»¶
    with open(output_file, 'w') as f:
        f.write('\n'.join(yolo_annotations))
    
    return True


def process_labelme_folder(input_folder, output_folder, label_map, verbose=True):
    """
    å¤„ç†è¾“å…¥æ–‡ä»¶å¤¹ä¸­çš„æ‰€æœ‰ JSON æ–‡ä»¶ï¼Œå¹¶å°†å…¶è½¬æ¢ä¸º YOLO11 æ ¼å¼çš„ TXT æ–‡ä»¶ã€‚
    """
    os.makedirs(output_folder, exist_ok=True)  # åˆ›å»ºè¾“å‡ºæ–‡ä»¶å¤¹
    converted_count = 0
    skipped_count = 0
    
    # è·å–æ‰€æœ‰JSONæ–‡ä»¶
    json_files = [f for f in os.listdir(input_folder) if f.endswith(".json")]
    if verbose:
        print(f"æ‰¾åˆ° {len(json_files)} ä¸ªJSONæ–‡ä»¶")
    
    for filename in json_files:
        json_path = os.path.join(input_folder, filename)
        if verbose:
            print(f"å¤„ç†æ–‡ä»¶: {filename}")
        
        # è°ƒç”¨è½¬æ¢å‡½æ•°å¹¶æ£€æŸ¥è¿”å›å€¼
        success = convert_labelme_to_yolo(json_path, output_folder, label_map)
        if success:
            converted_count += 1
        else:
            skipped_count += 1
    
    if verbose:
        print(f"æˆåŠŸè½¬æ¢ {converted_count} ä¸ªJSONæ ‡æ³¨æ–‡ä»¶")
        if skipped_count > 0:
            print(f"è·³è¿‡ {skipped_count} ä¸ªæœ‰é—®é¢˜çš„æ–‡ä»¶")
    
    return converted_count


def split_dataset(image_dir, label_dir, output_dir, train_rate=0.8, val_rate=0.1, test_rate=0.1):
    """
    æŒ‰æ¯”ä¾‹åˆ†å‰²æ•°æ®é›†ä¸ºè®­ç»ƒé›†ã€éªŒè¯é›†å’Œæµ‹è¯•é›†
    """
    # æ”¯æŒå¤šç§å›¾ç‰‡æ ¼å¼
    image_exts = ('.jpg', '.jpeg', '.png', '.bmp')
    images = [f for f in os.listdir(image_dir) if f.lower().endswith(image_exts)]
    
    # æ ¹æ®å›¾ç‰‡æ–‡ä»¶åç”Ÿæˆå¯¹åº”çš„æ ‡ç­¾æ–‡ä»¶åï¼ˆå‡è®¾æ ‡ç­¾æ ¼å¼ä¸º .txtï¼‰
    labels = [os.path.splitext(f)[0] + '.txt' for f in images]  

    # ç¡®ä¿å›¾ç‰‡å’Œæ ‡ç­¾æ–‡ä»¶ä¸€ä¸€å¯¹åº”
    valid_images = []
    for image, label in zip(images, labels):
        if os.path.exists(os.path.join(label_dir, label)):
            valid_images.append(image)
        else:
            print(f"Warning: å›¾ç‰‡ {image} å¯¹åº”çš„æ ‡ç­¾æ–‡ä»¶æœªæ‰¾åˆ°ï¼Œè·³è¿‡æ­¤å›¾ç‰‡")
    
    print(f"æ‰¾åˆ° {len(valid_images)} ä¸ªæœ‰æ•ˆçš„å›¾ç‰‡-æ ‡ç­¾å¯¹")
    
    if len(valid_images) == 0:
        raise ValueError("æ²¡æœ‰æ‰¾åˆ°æœ‰æ•ˆçš„å›¾ç‰‡-æ ‡ç­¾å¯¹ï¼")
    
    # ä½¿ç”¨æœ‰æ•ˆçš„å›¾ç‰‡åˆ—è¡¨è¿›è¡Œåˆ’åˆ†
    train_images, val_test_images = train_test_split(valid_images, test_size=(val_rate + test_rate), random_state=42)
    val_images, test_images = train_test_split(val_test_images, test_size=(test_rate / (val_rate + test_rate)), random_state=42)

    subsets = [('train', train_images), ('val', val_images), ('test', test_images)]

    # åˆ›å»ºè¾“å‡ºæ–‡ä»¶å¤¹å¹¶å¤åˆ¶æ–‡ä»¶
    for subset, subset_images in subsets:
        os.makedirs(f"{output_dir}/images/{subset}", exist_ok=True)
        os.makedirs(f"{output_dir}/labels/{subset}", exist_ok=True)
        
        for image in subset_images:
            # å¤åˆ¶å›¾ç‰‡æ–‡ä»¶
            shutil.copy(os.path.join(image_dir, image), f"{output_dir}/images/{subset}/{image}")
            # å¤åˆ¶å¯¹åº”çš„æ ‡ç­¾æ–‡ä»¶
            label_file = os.path.splitext(image)[0] + '.txt'
            shutil.copy(os.path.join(label_dir, label_file), f"{output_dir}/labels/{subset}/{label_file}")
    
    print(f"æ•°æ®é›†åˆ†å‰²å®Œæˆ:")
    print(f"  è®­ç»ƒé›†: {len(train_images)} ä¸ªæ ·æœ¬")
    print(f"  éªŒè¯é›†: {len(val_images)} ä¸ªæ ·æœ¬") 
    print(f"  æµ‹è¯•é›†: {len(test_images)} ä¸ªæ ·æœ¬")


def generate_data_yaml(output_dir, dataset_path, label_names):
    """
    ç”Ÿæˆdata.yamlé…ç½®æ–‡ä»¶
    """
    # å°†è·¯å¾„è½¬æ¢ä¸ºç»å¯¹è·¯å¾„
    train_path = os.path.abspath(os.path.join(dataset_path, "images/train"))
    val_path = os.path.abspath(os.path.join(dataset_path, "images/val"))
    test_path = os.path.abspath(os.path.join(dataset_path, "images/test"))
    
    # æ ¼å¼åŒ–ç±»åˆ«åç§°åˆ—è¡¨ï¼Œç¡®ä¿YAMLæ ¼å¼æ­£ç¡®ï¼ˆå•ç±»åˆ«æ—¶ä¹Ÿè¦æ˜¯åˆ—è¡¨æ ¼å¼ï¼‰
    names_str = str(label_names) if len(label_names) > 1 else f"['{label_names[0]}']"
    
    data_yaml_content = f"""train: {train_path}
val: {val_path}
test: {test_path}

nc: {len(label_names)}  # ç±»åˆ«æ•°é‡
names: {names_str}  # ç±»åˆ«åç§°ï¼Œéœ€ä¸æ ‡ç­¾æ–‡ä»¶ä¸­çš„ç±»åˆ«ä¸€è‡´
"""
    
    data_yaml_path = os.path.join(output_dir, 'data.yaml')
    with open(data_yaml_path, 'w', encoding='utf-8') as f:
        f.write(data_yaml_content)
    
    print(f"å·²ç”Ÿæˆ data.yaml æ–‡ä»¶: {data_yaml_path}")
    print(f"  - ç±»åˆ«æ•°é‡(nc): {len(label_names)}")
    print(f"  - ç±»åˆ«åç§°(names): {label_names}")
    return data_yaml_path


def generate_train_script(output_dir, dataset_name):
    """
    ç”Ÿæˆtrain.pyè®­ç»ƒè„šæœ¬
    """
    train_script_content = f"""from ultralytics.models import YOLO
import os

os.environ['KMP_DUPLICATE_LIB_OK'] = 'True'
 
if __name__ == '__main__':
    model = YOLO(model='/home/gdw/train-center/ultralytics/yolo11n.pt')
    model.train(
        data='./data.yaml',         # æ•°æ®é›†é…ç½®æ–‡ä»¶è·¯å¾„
        epochs=100,                 # è®­ç»ƒè½®æ•°
        batch=48,                   # æ‰¹æ¬¡å¤§å°
        device='1,2,3',             # ä½¿ç”¨çš„GPUè®¾å¤‡ç¼–å·
        workers=16,                 # æ•°æ®åŠ è½½çº¿ç¨‹æ•°
        lr0=0.01,                   # åˆå§‹å­¦ä¹ ç‡
        lrf=0.01,                   # æœ€ç»ˆå­¦ä¹ ç‡æ¯”ä¾‹
        momentum=0.937,             # ä¼˜åŒ–å™¨åŠ¨é‡
        weight_decay=0.0005,        # æƒé‡è¡°å‡
        optimizer='SGD',            # ä¼˜åŒ–å™¨ç±»å‹
        amp=False,                  # æ˜¯å¦å¯ç”¨æ··åˆç²¾åº¦è®­ç»ƒ
        project='train',       # è®­ç»ƒç»“æœä¿å­˜ç›®å½•
        name='{dataset_name}'
    )
"""
    
    train_script_path = os.path.join(output_dir, 'train.py')
    with open(train_script_path, 'w', encoding='utf-8') as f:
        f.write(train_script_content)
    
    print(f"å·²ç”Ÿæˆ train.py æ–‡ä»¶: {train_script_path}")
    return train_script_path


def main():
    parser = argparse.ArgumentParser(description='YOLOè®­ç»ƒæ•°æ®å‡†å¤‡å®Œæ•´ç®¡é“')
    parser.add_argument('-i', '--json_dir', default='../rack_data', help='Labelmeæ ‡æ³¨JSONæ–‡ä»¶å¤¹è·¯å¾„')
    parser.add_argument('-n', '--dataset_name', default='rack', help='æ•°æ®é›†åç§°')
    parser.add_argument('--train_ratio', type=float, default=0.8, help='è®­ç»ƒé›†æ¯”ä¾‹ (é»˜è®¤: 0.8)')
    parser.add_argument('--val_ratio', type=float, default=0.1, help='éªŒè¯é›†æ¯”ä¾‹ (é»˜è®¤: 0.1)')
    parser.add_argument('--test_ratio', type=float, default=0.1, help='æµ‹è¯•é›†æ¯”ä¾‹ (é»˜è®¤: 0.1)')
    
    args = parser.parse_args()
    
    # éªŒè¯å‚æ•°
    if not os.path.exists(args.json_dir):
        raise FileNotFoundError(f"JSONæ–‡ä»¶å¤¹ä¸å­˜åœ¨: {args.json_dir}")
    
    if abs(args.train_ratio + args.val_ratio + args.test_ratio - 1.0) > 0.001:
        raise ValueError("è®­ç»ƒé›†ã€éªŒè¯é›†ã€æµ‹è¯•é›†æ¯”ä¾‹ä¹‹å’Œå¿…é¡»ç­‰äº1.0")
    
    # ç”Ÿæˆæ•°æ®é›†åç§°
    if args.dataset_name:
        dataset_name = args.dataset_name
    else:
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        dataset_name = f"dataset_{timestamp}"
    
    print(f"å¼€å§‹å¤„ç†æ•°æ®é›†: {dataset_name}")
    
    # åˆ›å»ºè¾“å‡ºç›®å½•ç»“æ„
    datasets_dir = "./datasets"
    os.makedirs(datasets_dir, exist_ok=True)
    
    dataset_output_dir = os.path.join(datasets_dir, dataset_name)
    os.makedirs(dataset_output_dir, exist_ok=True)
    
    # è·å–è„šæœ¬æ‰€åœ¨ç›®å½•ï¼Œç”¨äºç”Ÿæˆé…ç½®æ–‡ä»¶
    script_dir = os.path.dirname(os.path.abspath(__file__))
    if not script_dir:
        script_dir = os.getcwd()
    
    print(f"é…ç½®æ–‡ä»¶å°†ä¿å­˜åˆ°: {script_dir}")
    
    try:
        # 1. è®¾ç½®å›ºå®šçš„æ ‡ç­¾æ˜ å°„ï¼ˆåªæœ‰ä¸€ä¸ªç±»åˆ«ï¼šNGï¼‰
        label_map = {'NG': 0}
        label_names = ['NG']
        print(f"âœ… ä½¿ç”¨å›ºå®šæ ‡ç­¾æ˜ å°„: NG -> 0")
        
        # 2. è½¬æ¢labelmeæ ‡æ³¨ä¸ºYOLOæ ¼å¼
        print("\næ­£åœ¨è½¬æ¢Labelmeæ ‡æ³¨ä¸ºYOLOæ ¼å¼...")
        temp_labels_dir = os.path.join(dataset_output_dir, "temp_labels")
        convert_count = process_labelme_folder(args.json_dir, temp_labels_dir, label_map)
        
        if convert_count == 0:
            raise ValueError("æ²¡æœ‰æ‰¾åˆ°å¯è½¬æ¢çš„JSONæ ‡æ³¨æ–‡ä»¶ï¼")
        
        # 3. åˆ†å‰²æ•°æ®é›†
        print("æ­£åœ¨åˆ†å‰²æ•°æ®é›†...")
        split_dataset(
            args.json_dir, 
            temp_labels_dir, 
            dataset_output_dir,
            args.train_ratio, 
            args.val_ratio, 
            args.test_ratio
        )
        
        # 4. æ¸…ç†ä¸´æ—¶æ ‡ç­¾æ–‡ä»¶å¤¹
        shutil.rmtree(temp_labels_dir)
        
        # 5. ç”Ÿæˆé…ç½®æ–‡ä»¶ï¼ˆç›´æ¥ç”Ÿæˆåœ¨è„šæœ¬åŒçº§ç›®å½•ï¼‰
        print("æ­£åœ¨ç”Ÿæˆé…ç½®æ–‡ä»¶...")
        data_yaml_path = generate_data_yaml(script_dir, dataset_output_dir, label_names)
        train_script_path = generate_train_script(script_dir, dataset_name)
        
        print(f"\nâœ… æ•°æ®é›†å‡†å¤‡å®Œæˆï¼")
        print(f"ğŸ“ æ•°æ®é›†ä½ç½®: {dataset_output_dir}")
        print(f"ğŸ“„ æ•°æ®é…ç½®: {data_yaml_path}")
        print(f"ğŸ“„ è®­ç»ƒè„šæœ¬: {train_script_path}")
        print(f"\nğŸš€ ä¸‹ä¸€æ­¥: åœ¨å½“å‰ç›®å½•è¿è¡Œ python train.py")
        
    except Exception as e:
        print(f"âŒ å¤„ç†è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {str(e)}")
        # æ¸…ç†å¯èƒ½åˆ›å»ºçš„ç›®å½•
        if os.path.exists(dataset_output_dir) and not os.listdir(dataset_output_dir):
            os.rmdir(dataset_output_dir)
        raise


if __name__ == '__main__':
    main()
